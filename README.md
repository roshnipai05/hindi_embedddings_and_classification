## Hindi NLP: Custom Word Embeddings & News Classification

This project implements a complete NLP pipeline for Hindi. It starts by curating a large Hindi text corpus, trains custom word embeddings using FastText, and finally utilizes these embeddings to build an LSTM-based Deep Learning model for classifying BBC Hindi news articles.

### Project Overview

The project is divided into three main stages:
1.  **Data Curation:** Streaming and cleaning the `ai4bharat/sangraha` dataset to build a high-quality Hindi corpus.
2.  **Word Representation:** Training a custom FastText (Skipgram) model to generate 100-dimensional Hindi word vectors.
3.  **Text Classification:** Building an LSTM model that uses the pre-trained vectors to classify news articles into categories (e.g., India, Sports, International).

### Directory Structure

Ensure your project directory is organized as follows:

```text
hindi_nlp_project/
│
├── data/
│   ├── hindi_corpus_clean.txt       # Generated by Script 1
│   └── bbc_hindi_news.csv           # Downloaded from Kaggle (rename it to this)
│
├── models/
│   ├── custom_hindi_vectors.bin     # Generated by Script 2
│   └── lstm_classifier.h5           # (Optional) Saved model from Script 3
│
├── 01_data_prep.py                  # Script 1: Download & Clean
├── 02_train_vectors.py              # Script 2: Train FastText & Compare
├── 03_lstm_classifier.py            # Script 3: LSTM Classification
├── requirements.txt                 # Dependencies
└── README.md                        # Project documentation
```

### Prerequisites & Installation
1. Python Compatibility
Recommended: Python 3.9 - 3.11.
If you are using Python 3.12 or 3.13, you must install the legacy Keras adapter (tf-keras) as described below to avoid compatibility issues with TensorFlow 2.16+.

2. Virtual Environment (Highly Recommended)
Create and activate a virtual environment to keep dependencies isolated:

**Windows:**
PowerShell
python -m venv .venv
.\.venv\Scripts\activate
Mac/Linux:

**Bash** 
python3 -m venv .venv
source .venv/bin/activate

3. Install Dependencies
Create a requirements.txt file with the following content:

Plaintext
datasets
fasttext-wheel
pandas
numpy
scikit-learn
tqdm
tensorflow
tf-keras
Then run:

Bash
pip install -r requirements.txt

Usage Guide
Run the scripts in the following order.

Step 1: Data Preparation
Streams the Sangraha dataset, cleans the text (removes English/symbols), and splits documents into sentences.

Bash
python 01_data_prep.py
Output: data/hindi_corpus_clean.txt (~2M sentences).

Time: 5–15 mins (depending on internet speed).

Step 2: Train Word Embeddings
Trains a FastText Skipgram model on the cleaned corpus. It also performs a qualitative check (finding neighbors for words like "Cricket" or "Government").

Bash
python 02_train_vectors.py
Output: models/custom_hindi_vectors.bin.

Time: 3–10 mins.

Step 3: Train LSTM Classifier
Loads the BBC News dataset and the custom FastText vectors. It trains an LSTM model to classify articles.

Bash
python 03_lstm_classifier.py
Output: Training logs, accuracy metrics, and evaluation results.

Time: < 5 mins.

Dataset Information
Pre-training Corpus: AI4Bharat Sangraha (Verified Hindi subset).
Classification Dataset: BBC Hindi News Articles (Kaggle).

Note: You must download the CSV from Kaggle manually and place it in the data/ folder as bbc_hindi_news.csv.

Troubleshooting
1. ImportError: cannot import name 'Tokenizer' from 'keras.preprocessing.text'

Cause: You are using TensorFlow 2.16+ which removed these tools.

Fix: Ensure you have installed tf-keras and that Script 3 includes the legacy fix:

Python
import os
os.environ["TF_USE_LEGACY_KERAS"] = "1"
import tf_keras as keras
2. Microsoft Visual C++ 14.0 is required

Cause: pip install fasttext tries to compile C++ code.

Fix: Use pip install fasttext-wheel instead for a pre-compiled binary.

3. "Read 800M words..." (Training takes forever)

Cause: The data prep script was saving whole documents instead of sentences.

Fix: Ensure you are using the updated 01_data_prep.py that splits text based on the Hindi full stop (।).

Results
Embeddings: You should see semantic relationships (e.g., King - Man + Woman ≈ Queen).

Classification: The LSTM model typically achieves 85-95% accuracy on the BBC News test set.